{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9008631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "970b4e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "    words = text.split()\n",
    "    tokens = []\n",
    "    tokens.extend(words)\n",
    "    for word in words:\n",
    "        for seed in all_seed_words:\n",
    "            if seed in word:\n",
    "                tokens.append(seed)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ad3447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IRTFIDF:\n",
    "    def __init__(self, X, vectorizer):\n",
    "        self.X = X\n",
    "        self.N = len(X)\n",
    "        self.vectorizer = vectorizer\n",
    "        self.X_tfidf = vectorizer.fit_transform(X)\n",
    "    \n",
    "    def compute_tfidf(self, X_idx, words):\n",
    "        score = 0\n",
    "        for w in words:\n",
    "            if w not in self.vectorizer.vocabulary_:\n",
    "                score += 0\n",
    "            else:\n",
    "                word_index = self.vectorizer.vocabulary_[w]\n",
    "                score += self.X_tfidf[X_idx, word_index]\n",
    "        return score\n",
    "        \n",
    "    def classify(self, seedwords):\n",
    "        documents_labels = []\n",
    "        for i in range(self.X.shape[0]):\n",
    "            scores = {}\n",
    "            for label, words in seedwords.items():\n",
    "                all_words = words + [label]\n",
    "                scores[label] = self.compute_tfidf(i, all_words)\n",
    "            if sum(scores.values()) == 0:\n",
    "                documents_labels.append(\"sci\")\n",
    "            else:\n",
    "                documents_labels.append(max(scores, key=scores.get))\n",
    "        return documents_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8382304",
   "metadata": {},
   "source": [
    "## IR-TF-IDF on 20 Newsgroup Dataset (Coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feeaeb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 Newsgroup Dataset (Coarse)\n",
    "with open(\"data/20news/coarse/df.pkl\", \"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "with open(\"data/20news/coarse/seedwords.json\", \"rb\") as file:\n",
    "    seedwords = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9467708",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"sentence\"]\n",
    "y = data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8601a0e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\", sublinear_tf=True)\n",
    "classifier = IRTFIDF(X, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75148664",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier.classify(seedwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f70b78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score (macro) using without hyperparameter tuning: 0.55792668405245\n",
      "F1_score (micro) using without hyperparameter tuning: 0.5477298866312503\n"
     ]
    }
   ],
   "source": [
    "f1_macro = f1_score(y,pred,average='macro')\n",
    "f1_micro = f1_score(y,pred,average='micro')\n",
    "print(f\"F1_score (macro) using without hyperparameter tuning: {f1_macro}\")\n",
    "print(f\"F1_score (micro) using without hyperparameter tuning: {f1_micro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b362d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seed_words = [item for sublist in [[key] + values for key, values in seedwords.items()] for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eb4695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eykim/.local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Using customer tokenizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, sublinear_tf=True)\n",
    "classifier = IRTFIDF(X, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a023745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier.classify(seedwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9c47606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score (macro) with hyperparameter tuning: 0.5210030142113452\n",
      "F1_score (micro) with hyperparameter tuning: 0.5395695273563722\n"
     ]
    }
   ],
   "source": [
    "f1_macro = f1_score(y,pred,average='macro')\n",
    "f1_micro = f1_score(y,pred,average='micro')\n",
    "print(f\"F1_score (macro) with hyperparameter tuning: {f1_macro}\")\n",
    "print(f\"F1_score (micro) with hyperparameter tuning: {f1_micro}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62334ea",
   "metadata": {},
   "source": [
    "## IR-TF-IDF on 20 Newsgroup Dataset (Fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "919c7009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 Newsgroup Dataset (Fine)\n",
    "with open(\"data/20news/fine/df.pkl\", \"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "with open(\"data/20news/fine/seedwords.json\", \"rb\") as file:\n",
    "    seedwords = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f38fb72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"sentence\"]\n",
    "y = data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02c19fc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\", sublinear_tf=True)\n",
    "classifier = IRTFIDF(X, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e873fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier.classify(seedwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38788743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score (macro) without hyperparameter tuning: 0.5225877902426144\n",
      "F1_score (micro) without hyperparameter tuning: 0.4753272358836738\n"
     ]
    }
   ],
   "source": [
    "f1_macro = f1_score(y,pred,average='macro')\n",
    "f1_micro = f1_score(y,pred,average='micro')\n",
    "print(f\"F1_score (macro) without hyperparameter tuning: {f1_macro}\")\n",
    "print(f\"F1_score (micro) without hyperparameter tuning: {f1_micro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "257b1233",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seed_words = [item for sublist in [[key] + values for key, values in seedwords.items()] for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b185bf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eykim/.local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Using custom tokenizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, sublinear_tf=True)\n",
    "classifier = IRTFIDF(X, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a387da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier.classify(seedwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ba87515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score (macro) with hyperparameter tuning: 0.5017943285513188\n",
      "F1_score (micro) with hyperparameter tuning: 0.4982748233747741\n"
     ]
    }
   ],
   "source": [
    "f1_macro = f1_score(y,pred,average='macro')\n",
    "f1_micro = f1_score(y,pred,average='micro')\n",
    "print(f\"F1_score (macro) with hyperparameter tuning: {f1_macro}\")\n",
    "print(f\"F1_score (micro) with hyperparameter tuning: {f1_micro}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b0ea84",
   "metadata": {},
   "source": [
    "## IR-TF-IDF on NYT Dataset (Coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ed9e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYT Dataset (Coarse)\n",
    "with open(\"data/nyt/coarse/df.pkl\", \"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "with open(\"data/nyt/coarse/seedwords.json\", \"rb\") as file:\n",
    "    seedwords = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7690fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"sentence\"]\n",
    "y = data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fc54b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "classifier = IRTFIDF(X, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "931e50dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier.classify(seedwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb5c9eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score (macro) without hyperparameter tuning: 0.48540181226284024\n",
      "F1_score (micro) without hyperparameter tuning: 0.6397154506810098\n"
     ]
    }
   ],
   "source": [
    "f1_macro = f1_score(y,pred,average='macro')\n",
    "f1_micro = f1_score(y,pred,average='micro')\n",
    "print(f\"F1_score (macro) without hyperparameter tuning: {f1_macro}\")\n",
    "print(f\"F1_score (micro) without hyperparameter tuning: {f1_micro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09bd9186",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seed_words = [item for sublist in [[key] + values for key, values in seedwords.items()] for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f99c607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eykim/.local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Using customer tokenizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, sublinear_tf=True)\n",
    "classifier = IRTFIDF(X, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00bd2464",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier.classify(seedwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34f6a7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score (macro) with hyperparameter tuning: 0.4362725704218248\n",
      "F1_score (micro) with hyperparameter tuning: 0.6267892773488332\n"
     ]
    }
   ],
   "source": [
    "f1_macro = f1_score(y,pred,average='macro')\n",
    "f1_micro = f1_score(y,pred,average='micro')\n",
    "print(f\"F1_score (macro) with hyperparameter tuning: {f1_macro}\")\n",
    "print(f\"F1_score (micro) with hyperparameter tuning: {f1_micro}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067b99ab",
   "metadata": {},
   "source": [
    "## IR-TF-IDF on NYT Dataset (Fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43138826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYT Dataset (Fine)\n",
    "with open(\"data/nyt/fine/df.pkl\", \"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "with open(\"data/nyt/fine/seedwords.json\", \"rb\") as file:\n",
    "    seedwords = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31582082",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"sentence\"]\n",
    "y = data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58228dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "classifier = IRTFIDF(X, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "432ced7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier.classify(seedwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0647cb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score (macro) without hyperparameter tuning: 0.5696809813758315\n",
      "F1_score (micro) without hyperparameter tuning: 0.5180012145397762\n"
     ]
    }
   ],
   "source": [
    "f1_macro = f1_score(y,pred,average='macro')\n",
    "f1_micro = f1_score(y,pred,average='micro')\n",
    "print(f\"F1_score (macro) without hyperparameter tuning: {f1_macro}\")\n",
    "print(f\"F1_score (micro) without hyperparameter tuning: {f1_micro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "204cd861",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seed_words = [item for sublist in [[key] + values for key, values in seedwords.items()] for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "005d3ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eykim/.local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Using custom tokenizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, sublinear_tf=True)\n",
    "classifier = IRTFIDF(X, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "537216ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier.classify(seedwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97f4b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score (macro) with hyperparameter tuning: 0.5342748585120182\n",
      "F1_score (micro) with hyperparameter tuning: 0.5224256094387091\n"
     ]
    }
   ],
   "source": [
    "f1_macro = f1_score(y,pred,average='macro')\n",
    "f1_micro = f1_score(y,pred,average='micro')\n",
    "print(f\"F1_score (macro) with hyperparameter tuning: {f1_macro}\")\n",
    "print(f\"F1_score (micro) with hyperparameter tuning: {f1_micro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e288f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
